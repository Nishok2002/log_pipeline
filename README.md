# Real-Time Log Processing Pipeline (Mock AWS + Python)

## ğŸ“Œ Problem Statement
This project simulates a **real-time log processing pipeline** using Python and AWS concepts.  
It ingests JSON logs, validates + transforms them, and stores results in Parquet (valid) or JSON (errors).  
The design mirrors an AWS architecture with **S3 â†’ Lambda â†’ S3 (clean/error) â†’ CloudWatch â†’ API Gateway**.

---

## ğŸ› ï¸ Features
- **Validation**: Ensures `timestamp`, `user_id`, `action` fields exist.
- **Transformation**:
  - Convert timestamp into `YYYY-MM-DD HH:MM:SS`
  - Add `day_of_week`
- **Storage**:
  - Clean logs â†’ Parquet (columnar format)
  - Invalid logs â†’ JSON Lines
- **Monitoring**: Logs metrics (#processed, #errors).
- **REST API**: Query `/logins_today` to check how many login actions happened today.

---

## ğŸ“‚ Files
- `processor.py` â†’ validation + transformation
- `storage.py` â†’ write Parquet + JSONL
- `lambda_handler.py` â†’ AWS Lambdaâ€“style function
- `pipeline_moto.py` â†’ simulates S3 event â†’ Lambda trigger (using Moto)
- `api.py` â†’ FastAPI API to query clean logs
- `requirements.txt` â†’ Python dependencies

---

## ğŸš€ How to Run

### 1. Setup environment
```bash
python -m venv venv
source venv/bin/activate   # mac/linux
venv\Scripts\activate    # windows
pip install -r requirements.txt
```

### 2. Run pipeline (Moto simulation)
```bash
python pipeline_moto.py
```
You should see logs like:
```
Lambda result: {'processed': 3, 'valid': 1, 'errors': 2}
Wrote local copy: data/clean/clean_from_moto.parquet
```

### 3. Start API
```bash
uvicorn api:app --reload
```

### 4. Test API
In a browser or terminal:
```
http://127.0.0.1:8000/logins_today
```

Expected response (if todayâ€™s date exists in logs):
```json
{"logins_today": 1}
```

Swagger UI docs:
```
http://127.0.0.1:8000/docs
```

---

## ğŸ“Š AWS Architecture

```
S3 (input) â†’ Lambda â†’ S3 (clean/error)
                     â†“
                CloudWatch (metrics)
                     â†“
           API Gateway â†’ /logins_today
```

## ğŸ“Œ Failure Handling & Monitoring
- Invalid logs â†’ stored in **error S3 bucket**.
- Malformed files â†’ logged as errors in CloudWatch.
- Lambda errors â†’ automatically retried; failed events can go to a **Dead Letter Queue (DLQ)**.
- Monitoring â†’ CloudWatch tracks processed vs failed counts; alerts via SNS/email if thresholds exceeded.


